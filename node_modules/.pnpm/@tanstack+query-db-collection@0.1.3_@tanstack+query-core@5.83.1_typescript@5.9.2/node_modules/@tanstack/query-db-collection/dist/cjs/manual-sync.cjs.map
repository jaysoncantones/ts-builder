{"version":3,"file":"manual-sync.cjs","sources":["../../src/manual-sync.ts"],"sourcesContent":["import {\n  DeleteOperationItemNotFoundError,\n  DuplicateKeyInBatchError,\n  SyncNotInitializedError,\n  UpdateOperationItemNotFoundError,\n} from \"./errors\"\nimport type { QueryClient } from \"@tanstack/query-core\"\nimport type { ChangeMessage, Collection } from \"@tanstack/db\"\n\n// Types for sync operations\nexport type SyncOperation<\n  TRow extends object,\n  TKey extends string | number = string | number,\n  TInsertInput extends object = TRow,\n> =\n  | { type: `insert`; data: TInsertInput | Array<TInsertInput> }\n  | { type: `update`; data: Partial<TRow> | Array<Partial<TRow>> }\n  | { type: `delete`; key: TKey | Array<TKey> }\n  | { type: `upsert`; data: Partial<TRow> | Array<Partial<TRow>> }\n\nexport interface SyncContext<\n  TRow extends object,\n  TKey extends string | number = string | number,\n> {\n  collection: Collection<TRow>\n  queryClient: QueryClient\n  queryKey: Array<unknown>\n  getKey: (item: TRow) => TKey\n  begin: () => void\n  write: (message: Omit<ChangeMessage<TRow>, `key`>) => void\n  commit: () => void\n}\n\ninterface NormalizedOperation<\n  TRow extends object,\n  TKey extends string | number = string | number,\n> {\n  type: `insert` | `update` | `delete` | `upsert`\n  key: TKey\n  data?: TRow | Partial<TRow>\n}\n\n// Normalize operations into a consistent format\nfunction normalizeOperations<\n  TRow extends object,\n  TKey extends string | number = string | number,\n  TInsertInput extends object = TRow,\n>(\n  ops:\n    | SyncOperation<TRow, TKey, TInsertInput>\n    | Array<SyncOperation<TRow, TKey, TInsertInput>>,\n  ctx: SyncContext<TRow, TKey>\n): Array<NormalizedOperation<TRow, TKey>> {\n  const operations = Array.isArray(ops) ? ops : [ops]\n  const normalized: Array<NormalizedOperation<TRow, TKey>> = []\n\n  for (const op of operations) {\n    if (op.type === `delete`) {\n      const keys = Array.isArray(op.key) ? op.key : [op.key]\n      for (const key of keys) {\n        normalized.push({ type: `delete`, key })\n      }\n    } else {\n      const items = Array.isArray(op.data) ? op.data : [op.data]\n      for (const item of items) {\n        let key: TKey\n        if (op.type === `update`) {\n          // For updates, we need to get the key from the partial data\n          key = ctx.getKey(item as TRow)\n        } else {\n          // For insert/upsert, validate and resolve the full item first\n          const resolved = ctx.collection.validateData(\n            item,\n            op.type === `upsert` ? `insert` : op.type\n          )\n          key = ctx.getKey(resolved)\n        }\n        normalized.push({ type: op.type, key, data: item })\n      }\n    }\n  }\n\n  return normalized\n}\n\n// Validate operations before executing\nfunction validateOperations<\n  TRow extends object,\n  TKey extends string | number = string | number,\n>(\n  operations: Array<NormalizedOperation<TRow, TKey>>,\n  ctx: SyncContext<TRow, TKey>\n): void {\n  const seenKeys = new Set<TKey>()\n\n  for (const op of operations) {\n    // Check for duplicate keys within the batch\n    if (seenKeys.has(op.key)) {\n      throw new DuplicateKeyInBatchError(op.key)\n    }\n    seenKeys.add(op.key)\n\n    // Validate operation-specific requirements\n    if (op.type === `update`) {\n      if (!ctx.collection.has(op.key)) {\n        throw new UpdateOperationItemNotFoundError(op.key)\n      }\n    } else if (op.type === `delete`) {\n      if (!ctx.collection.has(op.key)) {\n        throw new DeleteOperationItemNotFoundError(op.key)\n      }\n    }\n  }\n}\n\n// Execute a batch of operations\nexport function performWriteOperations<\n  TRow extends object,\n  TKey extends string | number = string | number,\n  TInsertInput extends object = TRow,\n>(\n  operations:\n    | SyncOperation<TRow, TKey, TInsertInput>\n    | Array<SyncOperation<TRow, TKey, TInsertInput>>,\n  ctx: SyncContext<TRow, TKey>\n): void {\n  const normalized = normalizeOperations(operations, ctx)\n  validateOperations(normalized, ctx)\n\n  ctx.begin()\n\n  for (const op of normalized) {\n    switch (op.type) {\n      case `insert`: {\n        const resolved = ctx.collection.validateData(op.data, `insert`)\n        ctx.write({\n          type: `insert`,\n          value: resolved,\n        })\n        break\n      }\n      case `update`: {\n        const currentItem = ctx.collection.get(op.key)!\n        const updatedItem = {\n          ...currentItem,\n          ...op.data,\n        }\n        const resolved = ctx.collection.validateData(\n          updatedItem,\n          `update`,\n          op.key\n        )\n        ctx.write({\n          type: `update`,\n          value: resolved,\n        })\n        break\n      }\n      case `delete`: {\n        const currentItem = ctx.collection.get(op.key)!\n        ctx.write({\n          type: `delete`,\n          value: currentItem,\n        })\n        break\n      }\n      case `upsert`: {\n        const resolved = ctx.collection.validateData(\n          op.data,\n          ctx.collection.has(op.key) ? `update` : `insert`,\n          op.key\n        )\n        if (ctx.collection.has(op.key)) {\n          ctx.write({\n            type: `update`,\n            value: resolved,\n          })\n        } else {\n          ctx.write({\n            type: `insert`,\n            value: resolved,\n          })\n        }\n        break\n      }\n    }\n  }\n\n  ctx.commit()\n\n  // Update query cache after successful commit\n  const updatedData = ctx.collection.toArray\n  ctx.queryClient.setQueryData(ctx.queryKey, updatedData)\n}\n\n// Factory function to create write utils\nexport function createWriteUtils<\n  TRow extends object,\n  TKey extends string | number = string | number,\n  TInsertInput extends object = TRow,\n>(getContext: () => SyncContext<TRow, TKey> | null) {\n  function ensureContext(): SyncContext<TRow, TKey> {\n    const context = getContext()\n    if (!context) {\n      throw new SyncNotInitializedError()\n    }\n    return context\n  }\n\n  return {\n    writeInsert(data: TInsertInput | Array<TInsertInput>) {\n      const ctx = ensureContext()\n      performWriteOperations({ type: `insert`, data }, ctx)\n    },\n\n    writeUpdate(data: Partial<TRow> | Array<Partial<TRow>>) {\n      const ctx = ensureContext()\n      performWriteOperations({ type: `update`, data }, ctx)\n    },\n\n    writeDelete(key: TKey | Array<TKey>) {\n      const ctx = ensureContext()\n      performWriteOperations({ type: `delete`, key }, ctx)\n    },\n\n    writeUpsert(data: Partial<TRow> | Array<Partial<TRow>>) {\n      const ctx = ensureContext()\n      performWriteOperations({ type: `upsert`, data }, ctx)\n    },\n\n    writeBatch(operations: Array<SyncOperation<TRow, TKey, TInsertInput>>) {\n      const ctx = ensureContext()\n      performWriteOperations(operations, ctx)\n    },\n  }\n}\n"],"names":["DuplicateKeyInBatchError","UpdateOperationItemNotFoundError","DeleteOperationItemNotFoundError","SyncNotInitializedError"],"mappings":";;;AA2CA,SAAS,oBAKP,KAGA,KACwC;AACxC,QAAM,aAAa,MAAM,QAAQ,GAAG,IAAI,MAAM,CAAC,GAAG;AAClD,QAAM,aAAqD,CAAA;AAE3D,aAAW,MAAM,YAAY;AAC3B,QAAI,GAAG,SAAS,UAAU;AACxB,YAAM,OAAO,MAAM,QAAQ,GAAG,GAAG,IAAI,GAAG,MAAM,CAAC,GAAG,GAAG;AACrD,iBAAW,OAAO,MAAM;AACtB,mBAAW,KAAK,EAAE,MAAM,UAAU,KAAK;AAAA,MACzC;AAAA,IACF,OAAO;AACL,YAAM,QAAQ,MAAM,QAAQ,GAAG,IAAI,IAAI,GAAG,OAAO,CAAC,GAAG,IAAI;AACzD,iBAAW,QAAQ,OAAO;AACxB,YAAI;AACJ,YAAI,GAAG,SAAS,UAAU;AAExB,gBAAM,IAAI,OAAO,IAAY;AAAA,QAC/B,OAAO;AAEL,gBAAM,WAAW,IAAI,WAAW;AAAA,YAC9B;AAAA,YACA,GAAG,SAAS,WAAW,WAAW,GAAG;AAAA,UAAA;AAEvC,gBAAM,IAAI,OAAO,QAAQ;AAAA,QAC3B;AACA,mBAAW,KAAK,EAAE,MAAM,GAAG,MAAM,KAAK,MAAM,MAAM;AAAA,MACpD;AAAA,IACF;AAAA,EACF;AAEA,SAAO;AACT;AAGA,SAAS,mBAIP,YACA,KACM;AACN,QAAM,+BAAe,IAAA;AAErB,aAAW,MAAM,YAAY;AAE3B,QAAI,SAAS,IAAI,GAAG,GAAG,GAAG;AACxB,YAAM,IAAIA,OAAAA,yBAAyB,GAAG,GAAG;AAAA,IAC3C;AACA,aAAS,IAAI,GAAG,GAAG;AAGnB,QAAI,GAAG,SAAS,UAAU;AACxB,UAAI,CAAC,IAAI,WAAW,IAAI,GAAG,GAAG,GAAG;AAC/B,cAAM,IAAIC,OAAAA,iCAAiC,GAAG,GAAG;AAAA,MACnD;AAAA,IACF,WAAW,GAAG,SAAS,UAAU;AAC/B,UAAI,CAAC,IAAI,WAAW,IAAI,GAAG,GAAG,GAAG;AAC/B,cAAM,IAAIC,OAAAA,iCAAiC,GAAG,GAAG;AAAA,MACnD;AAAA,IACF;AAAA,EACF;AACF;AAGO,SAAS,uBAKd,YAGA,KACM;AACN,QAAM,aAAa,oBAAoB,YAAY,GAAG;AACtD,qBAAmB,YAAY,GAAG;AAElC,MAAI,MAAA;AAEJ,aAAW,MAAM,YAAY;AAC3B,YAAQ,GAAG,MAAA;AAAA,MACT,KAAK,UAAU;AACb,cAAM,WAAW,IAAI,WAAW,aAAa,GAAG,MAAM,QAAQ;AAC9D,YAAI,MAAM;AAAA,UACR,MAAM;AAAA,UACN,OAAO;AAAA,QAAA,CACR;AACD;AAAA,MACF;AAAA,MACA,KAAK,UAAU;AACb,cAAM,cAAc,IAAI,WAAW,IAAI,GAAG,GAAG;AAC7C,cAAM,cAAc;AAAA,UAClB,GAAG;AAAA,UACH,GAAG,GAAG;AAAA,QAAA;AAER,cAAM,WAAW,IAAI,WAAW;AAAA,UAC9B;AAAA,UACA;AAAA,UACA,GAAG;AAAA,QAAA;AAEL,YAAI,MAAM;AAAA,UACR,MAAM;AAAA,UACN,OAAO;AAAA,QAAA,CACR;AACD;AAAA,MACF;AAAA,MACA,KAAK,UAAU;AACb,cAAM,cAAc,IAAI,WAAW,IAAI,GAAG,GAAG;AAC7C,YAAI,MAAM;AAAA,UACR,MAAM;AAAA,UACN,OAAO;AAAA,QAAA,CACR;AACD;AAAA,MACF;AAAA,MACA,KAAK,UAAU;AACb,cAAM,WAAW,IAAI,WAAW;AAAA,UAC9B,GAAG;AAAA,UACH,IAAI,WAAW,IAAI,GAAG,GAAG,IAAI,WAAW;AAAA,UACxC,GAAG;AAAA,QAAA;AAEL,YAAI,IAAI,WAAW,IAAI,GAAG,GAAG,GAAG;AAC9B,cAAI,MAAM;AAAA,YACR,MAAM;AAAA,YACN,OAAO;AAAA,UAAA,CACR;AAAA,QACH,OAAO;AACL,cAAI,MAAM;AAAA,YACR,MAAM;AAAA,YACN,OAAO;AAAA,UAAA,CACR;AAAA,QACH;AACA;AAAA,MACF;AAAA,IAAA;AAAA,EAEJ;AAEA,MAAI,OAAA;AAGJ,QAAM,cAAc,IAAI,WAAW;AACnC,MAAI,YAAY,aAAa,IAAI,UAAU,WAAW;AACxD;AAGO,SAAS,iBAId,YAAkD;AAClD,WAAS,gBAAyC;AAChD,UAAM,UAAU,WAAA;AAChB,QAAI,CAAC,SAAS;AACZ,YAAM,IAAIC,OAAAA,wBAAA;AAAA,IACZ;AACA,WAAO;AAAA,EACT;AAEA,SAAO;AAAA,IACL,YAAY,MAA0C;AACpD,YAAM,MAAM,cAAA;AACZ,6BAAuB,EAAE,MAAM,UAAU,KAAA,GAAQ,GAAG;AAAA,IACtD;AAAA,IAEA,YAAY,MAA4C;AACtD,YAAM,MAAM,cAAA;AACZ,6BAAuB,EAAE,MAAM,UAAU,KAAA,GAAQ,GAAG;AAAA,IACtD;AAAA,IAEA,YAAY,KAAyB;AACnC,YAAM,MAAM,cAAA;AACZ,6BAAuB,EAAE,MAAM,UAAU,IAAA,GAAO,GAAG;AAAA,IACrD;AAAA,IAEA,YAAY,MAA4C;AACtD,YAAM,MAAM,cAAA;AACZ,6BAAuB,EAAE,MAAM,UAAU,KAAA,GAAQ,GAAG;AAAA,IACtD;AAAA,IAEA,WAAW,YAA4D;AACrE,YAAM,MAAM,cAAA;AACZ,6BAAuB,YAAY,GAAG;AAAA,IACxC;AAAA,EAAA;AAEJ;;;"}